{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwhitz/ts-trove/blob/master/notebooks/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVkS8EnJ6hfS"
      },
      "source": [
        "# Time Series Classification\n",
        "\n",
        "This notebook explores various time series classification techniques. It makes much fuller use of the bearings dataset also explored in the signal analysis notebook.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Time series classification involves assigning time series instances to predefined categories. This notebook will cover:\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "> 1 [Data Preparation](#Data-Preparation)\n",
        "\n",
        "1.1. [Data Download](##Data-Download)\n",
        "\n",
        "1.2 [Data Organization](##Data-Organization)\n",
        "\n",
        "> 2 [Utility Functions](#Training-Functions)\n",
        "\n",
        "2.1 [Data Loader](##Data-Loader)\n",
        "\n",
        "> 3 [Time Series Classification with SciKit](#Scikit-Functions)\n",
        "\n",
        "3.1 [Scikit Trainer and Evaluator](##Scikit-Trainer-and-Evaluator)\n",
        "\n",
        "> 4 [Deep Learning Models](#Deep-Learning-Models)\n",
        "\n",
        "4.1 [PyTorch Trainer and Evaluator](##-Trainer-and-Evaluator)\n",
        "\n",
        "4.2 [Fully Connected Neural Networks]()\n",
        "\n",
        "4.3 [Recurrent Neural Networks]()\n",
        "\n",
        "4.3.1 [Classic Recurrent Neural Network]()\n",
        "\n",
        "4.3.2 [Long Short Term Memory (LSTM) Neural Network]()\n",
        "\n",
        "4.3.3 [Gated Recurrent Neural Network]()\n",
        "\n",
        "4.4 [Convolutional Neural Networks]()\n",
        "\n",
        "4.4.1 [1D Convolutional Neural Network]()\n",
        "\n",
        "4.4.2 [Temporal Convolutional Network]()\n",
        "\n",
        "4.5 [Attention Based Models]()\n",
        "\n",
        "4.5.1 [LSTM with Attention]()\n",
        "\n",
        "4.5.2 [Time Series Transformer]()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKXciZyo6hfT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pathlib\n",
        "import shutil\n",
        "import kagglehub\n",
        "\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "GbBKg-yEXhf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs3qdujLVjZK"
      },
      "outputs": [],
      "source": [
        "!pip install cesium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlDAmb6rUOA0"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "## Data Overview\n",
        "\n",
        "**What is this dataset?**\n",
        "\n",
        "This is a collection of vibration data from electric motor bearings. Bearings those small spinning parts that let machinery rotate smoothly. Think of a bearing like the axle in a wheel: it's got little metal balls inside that roll around, letting a shaft spin with barely any friction.\n",
        "\n",
        "**Why was this dataset created?**\n",
        "\n",
        "The researchers at Case Western Reserve University deliberately damaged bearings in different ways, then recorded how the motor vibrated as a result. They made tiny cracks of various sizes (ranging from 7 to 40 thousandths of an inch) in the bearings, then attached vibration sensors to measure what happened.\n",
        "\n",
        "Cracks of different mm sizes were introduced on the outer race, inner race, and the balls themselves.\n",
        "\n",
        "![ball_bearing_diagram](https://www.globalspec.com/ImageRepository/LearnMore/20133/ball%20bearing5364b00280ef4db7b85dfba113f04556.png)\n",
        "\n",
        "The goal was to understand the relationship between bearing damage and vibration patterns, creating a reference library that shows what different types of bearing failure look like.\n",
        "\n",
        "**Why is it useful?**\n",
        "\n",
        "This data is incredibly useful for real-world maintenance and diagnostics. In factories and power plants, you can use vibration patterns to detect bearing problems before they cause catastrophic failures. By comparing vibrations from a running machine to patterns in this dataset, maintenance teams can identify early signs of wear, predict when a bearing will fail, and schedule repairs before expensive downtime happens. It's basically like a fingerprint database for bearing damage—once you know what a damaged bearing \"sounds like,\" you can spot trouble coming.\n",
        "\n",
        "**So what are we actually trying to predict?**\n",
        "\n",
        "Good question. We will try to train machine learning models to predict three things: 1) Is the bearing in normal operation? 2) If not, where is the crack? 3) And what size is it?\n",
        "\n",
        "2 and 3 of course become irrelevant if the bearing is in normal operation, but they allow us to go a step beyond simple detection of irregular operation.\n",
        "\n",
        "\n",
        "## Data Download\n",
        "\n",
        "The raw data can be downloaded directly from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak_iKkQdUCfF"
      },
      "outputs": [],
      "source": [
        "kagglepath = \"sufian79/cwru-mat-full-dataset\"\n",
        "path = kagglehub.dataset_download(kagglepath)\n",
        "\n",
        "\n",
        "pathlib.Path(f\"./{kagglepath.split('/')[-1]}\").mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, f\"./{kagglepath.split('/')[-1]}\", dirs_exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvtGS34aluAh"
      },
      "source": [
        "## Data Organization\n",
        "\n",
        "The raw data is a collection of numbered mat files and requires reference back to the [original website](https://engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data) to make sense of. I've gone ahead and done that with the JSON structure below.\n",
        "\n",
        "The data is organized at top-level describing the type of fault, or lack thereof with \"normal\" sample files are the motor operating without faults. The next level down is the sampling rate, followed by the location where the crack was introduced (IR being inner race, B being ball, OR being outer race) and then finally, the size of the cracks ranging from 7 to 21 mm.\n",
        "\n",
        "The code below this cell moves the individual samples into folders matching the structure below, which aligns with how PyTorch's DataSet and DataLoader work (we will make it work for scikit too)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe1oXdcK2h1E"
      },
      "outputs": [],
      "source": [
        "folder_structure = {\n",
        "  \"normal\": {\n",
        "    \"48k\": [\"97\", \"98\", \"99\", \"100\"]\n",
        "  },\n",
        "  \"drive_end_fault\": {\n",
        "    \"12k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"105\", \"106\", \"107\", \"108\"],\n",
        "        \"014\": [\"169\", \"170\", \"171\", \"172\"],\n",
        "        \"021\": [\"209\", \"210\", \"211\", \"212\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"118\", \"119\", \"120\", \"121\"],\n",
        "        \"014\": [\"185\", \"186\", \"187\", \"188\"],\n",
        "        \"021\": [\"222\", \"223\", \"224\", \"225\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"130\", \"131\", \"132\", \"133\"],\n",
        "        \"014\": [\"197\", \"198\", \"199\", \"200\"],\n",
        "        \"021\": [\"234\", \"235\", \"236\", \"237\"]\n",
        "      }\n",
        "    },\n",
        "\n",
        "    \"48k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"109\", \"110\", \"111\", \"112\"],\n",
        "        \"014\": [\"174\", \"175\", \"176\", \"177\"],\n",
        "        \"021\": [\"213\", \"214\", \"215\", \"217\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"122\", \"123\", \"124\", \"125\"],\n",
        "        \"014\": [\"189\", \"190\", \"191\", \"192\"],\n",
        "        \"021\": [\"226\", \"227\", \"228\", \"229\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"135\", \"136\", \"137\", \"138\"],\n",
        "        \"014\": [\"201\", \"202\", \"203\", \"204\"],\n",
        "        \"021\": [\"238\", \"239\", \"240\", \"241\"]\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "\n",
        "  \"fan_end_fault\": {\n",
        "    \"12k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"278\", \"279\", \"280\", \"281\"],\n",
        "        \"014\": [\"274\", \"275\", \"276\", \"277\"],\n",
        "        \"021\": [\"270\", \"271\", \"272\", \"273\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"282\", \"283\", \"284\", \"285\"],\n",
        "        \"014\": [\"286\", \"287\", \"288\", \"289\"],\n",
        "        \"021\": [\"290\", \"291\", \"292\", \"293\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"298\", \"299\", \"300\", \"301\"],\n",
        "        \"014\": [\"309\", \"310\", \"311\", \"312\"],\n",
        "        \"021\": [\"315\", \"316\", \"317\", \"318\"]\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUY9UIluUtx-"
      },
      "outputs": [],
      "source": [
        "SOURCE_DIR = \"cwru-mat-full-dataset/\"\n",
        "TARGET_DIR = \"classification-cwru-mat-organized\"\n",
        "FILE_EXTENSION = \".mat\"\n",
        "\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def move_file(file_id, dest_dir):\n",
        "    filename = file_id + FILE_EXTENSION\n",
        "    src_path = os.path.join(SOURCE_DIR, filename)\n",
        "    dst_path = os.path.join(dest_dir, filename)\n",
        "\n",
        "    if not os.path.exists(src_path):\n",
        "        print(f\"⚠️ Missing file: {src_path}\")\n",
        "        return\n",
        "\n",
        "    ensure_dir(dest_dir)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "def walk_structure(node, current_path):\n",
        "    if isinstance(node, list):\n",
        "        for file_id in node:\n",
        "            move_file(file_id, current_path)\n",
        "    elif isinstance(node, dict):\n",
        "        for key, child in node.items():\n",
        "            walk_structure(child, os.path.join(current_path, key))\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected structure type\")\n",
        "\n",
        "\n",
        "walk_structure(folder_structure, TARGET_DIR)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59mefCkU6hfU"
      },
      "source": [
        "# Utility Functions\n",
        "\n",
        "## Data Loader\n",
        "\n",
        "Before diving into modeling, we first need a consistent way to load and represent our time-series data. Since later sections will experiment with both deep learning and traditional classifiers, we define a reusable dataset structure that keeps preprocessing, sampling rate handling, and labels consistent across all methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9S8fo-16hfU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn import Module\n",
        "import scipy.io\n",
        "import enum\n",
        "\n",
        "# samplng rate enum\n",
        "class SamplingRate(enum.Enum):\n",
        "    sr12K = \"12k\"\n",
        "    sr48K = \"48k\"\n",
        "\n",
        "class FaultLocation(enum.Enum):\n",
        "    DE = \"drive_end_fault\"\n",
        "    FE = \"front_end_fault\"\n",
        "\n",
        "\n",
        "class BearingDataset(Dataset):\n",
        "    def __init__(self, file_paths, sampling_rate, fault_location, chunk_length, unified_label=True, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.fault_location = fault_location\n",
        "        self.chunk_length = chunk_length\n",
        "        self.transform = transform\n",
        "        self.unified_label = unified_label\n",
        "\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        self._organize_data()\n",
        "\n",
        "    def _organize_data(self):\n",
        "        for fp in self.file_paths:\n",
        "            if not pathlib.Path(fp).exists():\n",
        "                raise FileNotFoundError(f\"File not found: {fp}\")\n",
        "\n",
        "            mat_data = scipy.io.loadmat(fp)\n",
        "\n",
        "            key_to_match = f\"_{str(self.fault_location)[-2:]}_time\"\n",
        "            sensor_key = [key for key in mat_data.keys() if key_to_match in key][0]\n",
        "\n",
        "            signal = mat_data[sensor_key].squeeze()\n",
        "\n",
        "            n_chunks = len(signal) // self.chunk_length\n",
        "            truncated = signal[:n_chunks * self.chunk_length]\n",
        "\n",
        "            windows = truncated.reshape(n_chunks, self.chunk_length)\n",
        "\n",
        "            label_parts = fp.parent.parts\n",
        "            if label_parts[-2] == 'normal':\n",
        "                label_dict = {\n",
        "                    'normal': True,\n",
        "                    'fault_location': 'NA',\n",
        "                    'crack_size': 'NA'\n",
        "                }\n",
        "            else:\n",
        "                label_dict = {\n",
        "                    'normal': False,\n",
        "                    'fault_location': label_parts[-2],\n",
        "                    'crack_size': label_parts[-1]\n",
        "                }\n",
        "\n",
        "\n",
        "            for window in windows:\n",
        "              self.data.append(window)\n",
        "\n",
        "              if self.unified_label:\n",
        "                self.labels.append(f\"{label_dict['fault_location']}_{label_dict['crack_size']}\" if label_dict['normal'] == False else \"normal\")\n",
        "              else:\n",
        "                self.labels.append(label_dict)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        window = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            window = self.transform(window).astype('float32')\n",
        "\n",
        "        return window, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkVWvbwf6hfU"
      },
      "source": [
        "The dataset class above seeks to make the most of the data available in the bearings dataset by splitting each sample in the file into multiple overlapping windows. This increases the effective number of training samples and helps models learn more robust patterns. However, care must be taken to avoid data leakage between training and test sets when using overlapping windows - if we were to pull all the data and then split into train/test, windows from the same original sample could end up in both sets.\n",
        "\n",
        "To prevent this, we ensure that all windows derived from a given file are assigned to either the training or test set exclusively by splitting into train/test at the file level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2etv3hUJ6hfV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "all_files = list(Path(\"classification-cwru-mat-organized\").rglob(\"*.mat\"))\n",
        "\n",
        "# derive one label per file\n",
        "file_labels = [\n",
        "    '_'.join(f.parent.parts[-2:])\n",
        "    for f in all_files\n",
        "]\n",
        "\n",
        "train_files, test_files = train_test_split(\n",
        "    all_files,\n",
        "    test_size=.2,\n",
        "    shuffle=True,\n",
        "    stratify=file_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rekM3G0s6hfV"
      },
      "source": [
        "##\n",
        "\n",
        "We want to set up a class for testing different classification techniques on the bearings dataset. The class will accept a dataset object and classification model, and be able to train and evaluate the model consistently for metrics like accuracy, precision, recall, and F1-score as well as time for training and inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zq-Isg86hfV"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "\n",
        "class ClassificationTrainTestEvaluate(ABC):\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def classification_report(self):\n",
        "      \"\"\"\n",
        "      Creates a Plotly figure with three tabs, each showing:\n",
        "      - Confusion matrix heatmap\n",
        "      - Metrics summary table\n",
        "\n",
        "      One tab per task: Fault Detection, Fault Location, Crack Size\n",
        "      \"\"\"\n",
        "      from plotly.subplots import make_subplots\n",
        "      import plotly.graph_objects as go\n",
        "      from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "      # Define task names and their corresponding predictions/labels\n",
        "      tasks = {\n",
        "          'Fault Detection': {\n",
        "              'predictions': self.predictions_fault_detection,\n",
        "              'labels': self.test_y_fault_detection,\n",
        "              'class_names': ['Normal', 'Fault']\n",
        "          },\n",
        "          'Fault Location': {\n",
        "              'predictions': self.predictions_fault_location,\n",
        "              'labels': self.test_y_fault_location,\n",
        "              'class_names': ['B', 'IR', 'OR']\n",
        "          },\n",
        "          'Crack Size': {\n",
        "              'predictions': self.predictions_crack_size,\n",
        "              'labels': self.test_y_crack_size,\n",
        "              'class_names': ['007', '014', '021']\n",
        "          }\n",
        "      }\n",
        "\n",
        "      # Create subplots for each task\n",
        "      figs = []\n",
        "\n",
        "      for task_name, task_data in tasks.items():\n",
        "          predictions = task_data['predictions']\n",
        "          labels = task_data['labels']\n",
        "          class_names = task_data['class_names']\n",
        "\n",
        "          # Compute confusion matrix\n",
        "          cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "          # Compute metrics\n",
        "          accuracy = accuracy_score(labels, predictions)\n",
        "          precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
        "          recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
        "          f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "          # Create subplot layout\n",
        "          fig = make_subplots(\n",
        "              rows=1, cols=2,\n",
        "              column_widths=[0.6, 0.4],\n",
        "              specs=[[{\"type\": \"heatmap\"}, {\"type\": \"table\"}]],\n",
        "              subplot_titles=(\"Confusion Matrix\", \"Model Performance Metrics\")\n",
        "          )\n",
        "\n",
        "          # --- Confusion Matrix Heatmap ---\n",
        "          fig.add_trace(\n",
        "              go.Heatmap(\n",
        "                  z=cm,\n",
        "                  x=class_names,\n",
        "                  y=class_names,\n",
        "                  text=cm,\n",
        "                  texttemplate=\"%{text}\",\n",
        "                  colorscale=\"Blues\",\n",
        "                  showscale=False\n",
        "              ),\n",
        "              row=1, col=1\n",
        "          )\n",
        "\n",
        "          fig.update_xaxes(title_text=\"Predicted Label\", row=1, col=1)\n",
        "          fig.update_yaxes(title_text=\"True Label\", row=1, col=1)\n",
        "\n",
        "          # --- Metrics Table ---\n",
        "          fig.add_trace(\n",
        "              go.Table(\n",
        "                  header=dict(\n",
        "                      values=[\"Metric\", \"Value\"],\n",
        "                      fill_color=\"lightgrey\",\n",
        "                      align=\"center\"\n",
        "                  ),\n",
        "                  cells=dict(\n",
        "                      values=[\n",
        "                          [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
        "                          [f\"{accuracy:.4f}\", f\"{precision:.4f}\", f\"{recall:.4f}\", f\"{f1:.4f}\"]\n",
        "                      ],\n",
        "                      align=\"center\"\n",
        "                  )\n",
        "              ),\n",
        "              row=1, col=2\n",
        "          )\n",
        "\n",
        "          fig.update_layout(\n",
        "              title=f\"{task_name} - Evaluation Summary\",\n",
        "              height=500,\n",
        "              width=900,\n",
        "              showlegend=False\n",
        "          )\n",
        "\n",
        "          figs.append((task_name, fig))\n",
        "\n",
        "      # Display each figure\n",
        "      for task_name, fig in figs:\n",
        "          fig.show()\n",
        "\n",
        "class SciKitCTTE(ClassificationTrainTestEvaluate):\n",
        "    def prepare_data(self):\n",
        "        self.train_X, self.train_y = pd.DataFrame(), pd.Series()\n",
        "        print(\"Preparing training data...\")\n",
        "        for i in tqdm(range(len(self.train_dataset))):\n",
        "            X_chunk, label = self.train_dataset[i]\n",
        "\n",
        "            self.train_X = pd.concat([self.train_X, X_chunk], ignore_index=True)\n",
        "            self.train_y = pd.concat([self.train_y, pd.Series(label)], ignore_index=True)\n",
        "\n",
        "        self.test_X, self.test_y = pd.DataFrame(), pd.Series()\n",
        "        print(\"Preparing test data...\")\n",
        "        for i in tqdm(range(len(self.test_dataset))):\n",
        "            X_chunk, labels = self.test_dataset[i]\n",
        "\n",
        "            self.test_X = pd.concat([self.test_X, X_chunk], ignore_index=True)\n",
        "            self.test_y = pd.concat([self.test_y, pd.Series(labels)], ignore_index=True)\n",
        "\n",
        "    def train(self, train_X, train_y):\n",
        "        self.model.fit(train_X, train_y)\n",
        "        self.class_names = sorted(self.train_y.unique())\n",
        "\n",
        "    def evaluate(self, test_X, test_y):\n",
        "        self.predictions = self.model.predict(test_X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNl5Ed836hfV"
      },
      "source": [
        "# Feature Extraction + Feature Based Classification\n",
        "\n",
        "With a dataset abstraction in place, we can now explore different families of time-series classification techniques. The goal here is not only to compare performance, but also to understand how different representation choices affect model behavior on sensor-like signals.\n",
        "\n",
        "We begin with feature-based methods, which transform raw time-series into fixed-length statistical representations. These approaches are often strong baselines, easier to interpret, and computationally efficient compared to end-to-end deep learning models.\n",
        "\n",
        "### Feature Extraction\n",
        "\n",
        "We will implement a custom transformer class for the PyTorch dataset to extract statistical features using the `cesium` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZLiYT5C6hfV"
      },
      "outputs": [],
      "source": [
        "from cesium import featurize\n",
        "\n",
        "class FeatureExtractionTransform(Module):\n",
        "    def forward(self, window):\n",
        "        features_to_use = [\n",
        "            \"amplitude\",\n",
        "            \"percent_beyond_1_std\",\n",
        "            \"maximum\",\n",
        "            \"max_slope\",\n",
        "            \"median\",\n",
        "            \"median_absolute_deviation\",\n",
        "            \"percent_close_to_median\",\n",
        "            \"minimum\",\n",
        "            \"period_fast\",\n",
        "            \"skew\",\n",
        "            \"std\",\n",
        "        ]\n",
        "\n",
        "        fset = featurize.featurize_time_series(\n",
        "            times=np.arange(len(window)),\n",
        "            values=window,\n",
        "            errors=None,\n",
        "            features_to_use=features_to_use,\n",
        "        )\n",
        "\n",
        "        fset = fset.stack(future_stack=True)\n",
        "\n",
        "        return fset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHK6_RwQ6hfW"
      },
      "outputs": [],
      "source": [
        "train_dataset = BearingDataset(\n",
        "    train_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    chunk_length=1200,\n",
        "    unified_label=True,\n",
        "    transform=FeatureExtractionTransform()\n",
        ")\n",
        "\n",
        "test_dataset = BearingDataset(\n",
        "    test_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    chunk_length=1200,\n",
        "    unified_label=True,\n",
        "    transform=FeatureExtractionTransform()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZbEHq_n6hfW"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# sk_ctte = SciKitCTTE(\n",
        "#     train_dataset,\n",
        "#     test_dataset)\n",
        "\n",
        "# sk_ctte.prepare_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyKA2bPqXwU1"
      },
      "outputs": [],
      "source": [
        "# rfc = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "\n",
        "# sk_trainer = sk_ctte\n",
        "# sk_trainer.load_model(rfc)\n",
        "\n",
        "# sk_trainer.train(sk_trainer.train_X, sk_trainer.train_y)\n",
        "# sk_trainer.evaluate(sk_trainer.test_X, sk_trainer.test_y)\n",
        "# sk_trainer.classification_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wq0vPwDYPDv"
      },
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm = SVC(kernel='linear', C=.1, random_state=42)\n",
        "\n",
        "# sk_trainer = sk_ctte\n",
        "# sk_trainer.load_model(svm)\n",
        "\n",
        "# sk_trainer.train(sk_trainer.train_X, sk_trainer.train_y)\n",
        "# sk_trainer.evaluate(sk_trainer.test_X, sk_trainer.test_y)\n",
        "# sk_trainer.classification_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6j9W0Qc6hfW"
      },
      "source": [
        "# Deep Learning Models\n",
        "\n",
        "In this section, I will explore a wide variety of neural network models to find which can perform the best at what is essentially a many-to-one problem, where we are giving the model a dataset of many measurements of vibrational movement where ordering matters, because those measurements unfolded across time.\n",
        "\n",
        "4.1 [PyTorch Trainer and Evaluator](##\n",
        "PyTorch-Trainer-and-Evaluator)\n",
        "\n",
        "4.2 [Fully Connected Neural Networks]()\n",
        "\n",
        "4.3 [Recurrent Neural Networks]()\n",
        "\n",
        "4.3.1 [Classic Recurrent Neural Network]()\n",
        "\n",
        "4.3.2 [Long Short Term Memory (LSTM) Neural Network]()\n",
        "\n",
        "4.3.3 [Gated Recurrent Neural Network]()\n",
        "\n",
        "4.4 [Convolutional Neural Networks]()\n",
        "\n",
        "4.4.1 [1D Convolutional Neural Network]()\n",
        "\n",
        "4.4.2 [Temporal Convolutional Network]()\n",
        "\n",
        "4.5 [Attention Based Models]()\n",
        "\n",
        "4.5.1 [LSTM with Attention]()\n",
        "\n",
        "4.5.2 [Time Series Transformer]()\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnJFPo3RWk0h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aaqrd4QTsE8B"
      },
      "source": [
        "##PyTorch Trainer and Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qznbgXrq6hfW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch import Tensor, float32, LongTensor\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "class PyTorchCTTE(ClassificationTrainTestEvaluate):\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset, device='cpu', criterion=None, detection_weighting=1):\n",
        "        super().__init__(train_dataset, test_dataset)\n",
        "        self.device = device\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.target_mapping = {\n",
        "          'fault_location': {'B': 0, 'IR': 1, 'OR': 2, 'NA': 3},\n",
        "          'crack_size': {'007': 0, '014': 1, '021': 2, 'NA': 3}\n",
        "          }\n",
        "\n",
        "        self.train_dataset_mean = None\n",
        "        self.train_dataset_std = None\n",
        "        self.detection_weighting = detection_weighting\n",
        "        self.writer = SummaryWriter(\n",
        "            log_dir=os.path.join(\"runs\", time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "        )\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        \"\"\"Deep copy - recursively copies nested objects\"\"\"\n",
        "        return PyTorchCTTE(\n",
        "            copy.deepcopy(self.train_dataset, memo),\n",
        "            copy.deepcopy(self.test_dataset, memo),\n",
        "            copy.deepcopy(self.device, memo),\n",
        "            copy.deepcopy(self.criterion, memo)\n",
        "        )\n",
        "\n",
        "    def load_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def load_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=64, shuffle=True)\n",
        "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    def _evaluate_current_on_test(self, epoch: int):\n",
        "      self.model.eval()\n",
        "\n",
        "      total_loss = 0.0\n",
        "      correct_fd = 0\n",
        "      correct_fl = 0\n",
        "      correct_cs = 0\n",
        "      total_samples = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for batch_X, batch_y in self.test_dataloader:\n",
        "\n",
        "              batch_X = Tensor(batch_X.to(float32))\n",
        "              batch_X = (batch_X - batch_X.mean(dim=1, keepdim=True)) / (\n",
        "                  batch_X.std(dim=1, keepdim=True) + 1e-6\n",
        "              )\n",
        "              batch_X = batch_X.to(self.device)\n",
        "\n",
        "              # Labels\n",
        "              batch_y_fault_detection = LongTensor(\n",
        "                  [int(l) for l in batch_y['normal']]\n",
        "              ).to(self.device)\n",
        "\n",
        "              batch_y_fault_location = LongTensor(\n",
        "                  [self.target_mapping['fault_location'].get(l, 0)\n",
        "                  for l in batch_y['fault_location']]\n",
        "              ).to(self.device)\n",
        "\n",
        "              batch_y_crack_size = LongTensor(\n",
        "                  [self.target_mapping['crack_size'].get(l, 0)\n",
        "                  for l in batch_y['crack_size']]\n",
        "              ).to(self.device)\n",
        "\n",
        "              # Forward\n",
        "              fault_detection, fault_location, crack_size = self.model(batch_X)\n",
        "\n",
        "              # Loss\n",
        "              loss_fd = self.criterion(fault_detection, batch_y_fault_detection)\n",
        "              loss_fl = self.criterion(fault_location, batch_y_fault_location)\n",
        "              loss_cs = self.criterion(crack_size, batch_y_crack_size)\n",
        "\n",
        "              loss = (\n",
        "                  self.detection_weighting * loss_fd\n",
        "                  + loss_fl\n",
        "                  + loss_cs\n",
        "              )\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "              # Accuracy\n",
        "              _, pred_fd = torch.max(fault_detection, 1)\n",
        "              _, pred_fl = torch.max(fault_location, 1)\n",
        "              _, pred_cs = torch.max(crack_size, 1)\n",
        "\n",
        "              correct_fd += (pred_fd == batch_y_fault_detection).sum().item()\n",
        "              correct_fl += (pred_fl == batch_y_fault_location).sum().item()\n",
        "              correct_cs += (pred_cs == batch_y_crack_size).sum().item()\n",
        "\n",
        "              total_samples += batch_y_fault_detection.size(0)\n",
        "\n",
        "      avg_loss = total_loss / len(self.test_dataloader)\n",
        "      acc_fd = correct_fd / total_samples\n",
        "      acc_fl = correct_fl / total_samples\n",
        "      acc_cs = correct_cs / total_samples\n",
        "\n",
        "      # -------- TensorBoard Logging --------\n",
        "      self.writer.add_scalar(\"Epoch/Test_Loss\", avg_loss, epoch)\n",
        "      self.writer.add_scalar(\"Epoch/Test_Accuracy_Fault_Detection\", acc_fd, epoch)\n",
        "      self.writer.add_scalar(\"Epoch/Test_Accuracy_Fault_Location\", acc_fl, epoch)\n",
        "      self.writer.add_scalar(\"Epoch/Test_Accuracy_Crack_Size\", acc_cs, epoch)\n",
        "\n",
        "\n",
        "    def train(self, epochs: int, batch_size: int):\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        global_step = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            for batch_X, batch_y in self.train_dataloader:\n",
        "\n",
        "                # -------- Normalize Inputs --------\n",
        "                batch_X = Tensor(batch_X.to(float32))\n",
        "                batch_X = (batch_X - batch_X.mean(dim=1, keepdim=True)) / (\n",
        "                    batch_X.std(dim=1, keepdim=True) + 1e-6\n",
        "                )\n",
        "                batch_X = batch_X.to(self.device)\n",
        "\n",
        "                # -------- Labels --------\n",
        "                batch_y_fault_detection = [l for l in batch_y['normal']]\n",
        "                batch_y_fault_location = [\n",
        "                    self.target_mapping['fault_location'].get(l, 2)\n",
        "                    for l in batch_y['fault_location']\n",
        "                ]\n",
        "                batch_y_crack_size = [\n",
        "                    self.target_mapping['crack_size'].get(l, 2)\n",
        "                    for l in batch_y['crack_size']\n",
        "                ]\n",
        "\n",
        "                batch_y_fault_detection = LongTensor(batch_y_fault_detection).to(self.device)\n",
        "                batch_y_fault_location = LongTensor(batch_y_fault_location).to(self.device)\n",
        "                batch_y_crack_size = LongTensor(batch_y_crack_size).to(self.device)\n",
        "\n",
        "                # -------- Forward --------\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                fault_detection, fault_location, crack_size = self.model(batch_X)\n",
        "\n",
        "                loss_fault_detection = self.criterion(fault_detection, batch_y_fault_detection)\n",
        "                loss_fault_location = self.criterion(fault_location, batch_y_fault_location)\n",
        "                loss_crack_size = self.criterion(crack_size, batch_y_crack_size)\n",
        "\n",
        "                total_loss = (\n",
        "                    self.detection_weighting * loss_fault_detection\n",
        "                    + loss_fault_location\n",
        "                    + loss_crack_size\n",
        "                )\n",
        "\n",
        "                total_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += total_loss.item()\n",
        "\n",
        "                # -------- TensorBoard Batch Logging --------\n",
        "                self.writer.add_scalar(\"Batch/Loss\", total_loss.item(), global_step)\n",
        "                global_step += 1\n",
        "\n",
        "            avg_train_loss = epoch_loss / len(self.train_dataloader)\n",
        "\n",
        "            # -------- Epoch Logging --------\n",
        "            self.writer.add_scalar(\"Epoch/Train_Loss\", avg_train_loss, epoch)\n",
        "\n",
        "            # -------- Evaluate on Test Set During Training --------\n",
        "            self._evaluate_current_on_test(epoch)\n",
        "\n",
        "        self.writer.close()\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        self.predictions_fault_detection = []\n",
        "        self.predictions_fault_location = []\n",
        "        self.predictions_crack_size = []\n",
        "        self.test_y_fault_detection = []\n",
        "        self.test_y_fault_location = []\n",
        "        self.test_y_crack_size = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in self.test_dataloader:\n",
        "                batch_X = batch_X = Tensor(batch_X.to(float32))\n",
        "                batch_X = (batch_X - batch_X.mean(dim=1, keepdim=True)) / (batch_X.std(dim=1, keepdim=True) + 1e-6)\n",
        "                batch_X = batch_X.to(self.device)\n",
        "\n",
        "                fault_detection, fault_location, crack_size = self.model(batch_X)\n",
        "\n",
        "                # Get predictions for each task\n",
        "                _, pred_fd = torch.max(fault_detection, 1)\n",
        "                _, pred_fl = torch.max(fault_location, 1)\n",
        "                _, pred_cs = torch.max(crack_size, 1)\n",
        "\n",
        "                self.predictions_fault_detection.extend(pred_fd.cpu().numpy().tolist())\n",
        "                self.predictions_fault_location.extend(pred_fl.cpu().numpy().tolist())\n",
        "                self.predictions_crack_size.extend(pred_cs.cpu().numpy().tolist())\n",
        "\n",
        "                # Store true labels\n",
        "                self.test_y_fault_detection.extend([int(l) for l in batch_y['normal']])\n",
        "                self.test_y_fault_location.extend([self.target_mapping['fault_location'].get(l, 0) for l in batch_y['fault_location']])\n",
        "                self.test_y_crack_size.extend([self.target_mapping['crack_size'].get(l, 0) for l in batch_y['crack_size']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i5zcQ8IoQZm"
      },
      "source": [
        "### Datasets for Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xy3Y3G6oTA7"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "train_dataset = BearingDataset(\n",
        "    train_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    unified_label=False,\n",
        "    chunk_length=1200\n",
        ")\n",
        "\n",
        "test_dataset = BearingDataset(\n",
        "    test_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    unified_label=False,\n",
        "    chunk_length=1200\n",
        ")\n",
        "\n",
        "pytorch_ctte = PyTorchCTTE(\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    device=device,\n",
        "    criterion=CrossEntropyLoss()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aatdzOAusiOE"
      },
      "source": [
        "##Fully Connected Neural Network\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "A fully connected neural network treats each vibration sample as a fixed-length vector, learning relationships between all points in the signal simultaneously.\n",
        "\n",
        "Unlike sequential models, it makes no assumptions about temporal ordering — every input element is connected to every neuron in the next layer, allowing it to discover arbitrary correlations across the entire 1200-point reading. The first layer projects the raw signal into a 512-dimensional space, expanding the representation to capture a rich set of features, while the second layer compresses to 256 dimensions, acting as a bottleneck that forces the network to distill the most discriminative patterns. ReLU activations between layers introduce nonlinearity, enabling the network to learn complex decision boundaries that a simple linear classifier could not. This architecture is well suited for vibration classification when the signal length is fixed and the spatial relationships between measurement points carry meaningful information about fault characteristics, as it is in this project.\n",
        "\n",
        "\n",
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xjrzpaqsdZO"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class FCNN(nn.Module):\n",
        "    def __init__(self, input_dim=1200, num_fault_locations=4, num_crack_sizes=4):\n",
        "        super(FCNN, self).__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fault_detection_output = nn.Linear(256, 2)\n",
        "        self.fault_location_output = nn.Linear(256, num_fault_locations)\n",
        "        self.crack_size_output = nn.Linear(256, num_crack_sizes)\n",
        "\n",
        "        # Xavier initialization\n",
        "        nn.init.xavier_uniform_(self.fault_detection_output.weight)\n",
        "        nn.init.xavier_uniform_(self.fault_location_output.weight)\n",
        "        nn.init.xavier_uniform_(self.crack_size_output.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shared(x)\n",
        "\n",
        "        return (\n",
        "            torch.sigmoid(self.fault_detection_output(x)),\n",
        "            self.fault_location_output(x),\n",
        "            self.crack_size_output(x)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzTD3su0oKQ3"
      },
      "outputs": [],
      "source": [
        "fcnn_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "fcnn_model = FCNN(\n",
        "    input_dim=1200\n",
        ")\n",
        "\n",
        "fcnn_ctte.load_model(fcnn_model)\n",
        "\n",
        "fcnn_ctte.load_optimizer(\n",
        "    torch.optim.Adam(fcnn_model.parameters(), lr=1e-3)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHeN777EqEW8"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Kqr201ko55J"
      },
      "outputs": [],
      "source": [
        "fcnn_ctte.prepare_data()\n",
        "fcnn_ctte.train(epochs=20, batch_size=64)\n",
        "fcnn_ctte.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_df6kHjbp-Io"
      },
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FiqW9iap3kE"
      },
      "outputs": [],
      "source": [
        "fcnn_ctte.classification_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zHz6NsqoIW"
      },
      "source": [
        "## ResNet\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "\n",
        "### Model Anatomy\n",
        "\n",
        "**Residual Block Internals**\n",
        "\n",
        "In the architecture, residual blocks are defined as a separate module class outside the main ResNet1D class and then used in aggregate within the network definition block. Let's look at the definition of the internal components of *ResidualBlock1D* to start. It operates in two modes, depending if the output shape differs from the input shape - then it is downsampling - or not. Looking at the components as they are defined in the forward pass:\n",
        "\n",
        "* `shortcut` is defined differently if the block is performing downsampling or not. If it is not, then the shortcut is simply a passthrough. If it is performing downsampling, then the input is downsampled to the output dimensions using conv1d with a stride of two to halve the input dimension to the needed output dimension. Note that the identity is used to cache the input identity for later, it is not passed further along the network (yet).\n",
        "* `conv1` A convolutional layer is applied, but critically only to every other input (stride=2) when downsampling. When every other input is skipped, it halves the length of the output. Batch norm, ReLu and dropout are applied after to normalize, incorporate non-linearity, and prevent overfitting respectively.\n",
        "* `conv2` is a second convolution to help refine the features again without changing dimensions. Batch norm and dropout applied afterward, but not ReLu.\n",
        "* `out += identity` is the key move that makes this 'res' net. The input that we cached at the start is added in at the end of the convolutional layers. The final ReLU activates the combined result before passing to the next block.\n",
        "\n",
        "> This addition of the input layers at the end of this block is the core idea of ResNet. Instead of the network learning the full transformation F(x), it only needs to learn the difference from the input: F(x) = H(x) - x, so the output is x + F(x), the residuals in res net. This means if the optimal transformation is close to doing nothing, the network just learns to push F(x) toward zero — which is much easier than learning a full identity mapping from scratch. This is why deep ResNets can train where plain deep networks collapse.\n",
        "\n",
        "Now that we understand what is going on in a Residual Block, we will look at the whole architecture of the network.\n",
        "\n",
        "**Initial Convolutional Layer**\n",
        "\n",
        "To start, 32 one-dimensional [convolutional filters](https://developers.google.com/machine-learning/glossary#convolutional_filter) are applied to the vibration signal. The convolution uses a wide 1-dimensional kernel (16 samples) to learn filter parameters capable of capturing broad structural features like impulse responses, periodic oscillations, and transient events at different scales from the raw input before passing them into the residual stages. This produces a new value from the filter for each part of the original time series, for each of the 32 filters that are learned - the output shape is 1199 (samples, one lost due to padding) by 32 (learned filters). BatchNorm normalizes each of the 32 channels independently to zero mean and unit variance across the batch, and then ReLu zeros out all negative values.\n",
        "\n",
        "**Residual Blocks Layers**\n",
        "\n",
        "A series of eight residual blocks forms the heart of the network. They are arranged into four sequential groups, where each group halves the temporal dimension through stride-2 downsampling while progressively widening the channel count (32→32→64→128→128). The kernel size also steadily shrinks across groups (7→7→5→3), allowing later layers to learn increasingly fine-grained features now that earlier layers have already built up broad contextual awareness.\n",
        "\n",
        "> Each time a group downsamples, the temporal resolution is cut in half (e.g. 1199→600→300→150), but each remaining position now represents a wider window of the original signal. Combined with the residual connections carrying forward earlier representations, this means deeper blocks operate with an increasingly large receptive field. Each value in the compressed network is influenced by a broader stretch of the original vibration signal, allowing the network to pick up on longer-range structural patterns that wouldn't be visible at finer temporal scales.\n",
        "\n",
        "**Final Learning Layers**\n",
        "\n",
        "`AvgPool1D` is the adaptive average pooling layer collapses whatever temporal dimension remains (e.g. 150 time steps) down to a single value per channel by averaging across the entire length. This produces a fixed-size vector of 128 values — one summary statistic per learned feature channel — regardless of the original input length. This is what allows the network to transition from convolutional feature extraction into the fully connected classification heads.\n",
        "\n",
        "`fc_shared` is a fully connected layer that takes the 128-dimensional pooled vector and maps it to another 128-dimensional representation, followed by ReLU and dropout. It acts as a shared bottleneck that gives the network a chance to learn a final combined representation before branching into the three separate classification heads. Without it, each head would be working directly from the pooled convolutional features — this extra layer lets the network learn a task-aware remixing of those features that benefits all three outputs jointly.\n",
        "\n",
        "From the outputs of the `fc_shared` layer, the multiple classification heads are able to learn.\n",
        "\n",
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sPFfqDAq8P6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResidualBlock1D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=7, downsample=False, dropout=0.1):\n",
        "        super().__init__()\n",
        "        stride = 2 if downsample else 1\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        # residual block layer internals - definition\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               stride=stride, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               stride=1, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if downsample or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual block layer internals - implementation\n",
        "        identity = self.shortcut(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.dropout1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += identity\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class ResNet1D_pt(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_channels=1,\n",
        "                 num_location_classes=4,\n",
        "                 num_size_classes=4):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional Layer - definition\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 32, kernel_size=16, stride=1, padding=7),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # residual blocks layers - definition\n",
        "        self.layer1a = ResidualBlock1D(32, 32, kernel_size=7, downsample=False)\n",
        "        self.layer1b = ResidualBlock1D(32, 32, kernel_size=7, downsample=False)\n",
        "\n",
        "        self.layer2a = ResidualBlock1D(32, 64, kernel_size=7, downsample=True)   # 1200 -> 600\n",
        "        self.layer2b = ResidualBlock1D(64, 64, kernel_size=7, downsample=False)\n",
        "\n",
        "        self.layer3a = ResidualBlock1D(64, 128, kernel_size=5, downsample=True)  # 600 -> 300\n",
        "        self.layer3b = ResidualBlock1D(128, 128, kernel_size=5, downsample=False)\n",
        "\n",
        "        self.layer4a = ResidualBlock1D(128, 128, kernel_size=3, downsample=True) # 300 -> 150\n",
        "        self.layer4b = ResidualBlock1D(128, 128, kernel_size=3, downsample=False)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # Shared representation\n",
        "        self.fc_shared = nn.Linear(128, 128)\n",
        "\n",
        "        # Three classification heads\n",
        "        self.fc_fault_detection = nn.Linear(128, 2)\n",
        "        self.fc_fault_location = nn.Linear(128, num_location_classes)\n",
        "        self.fc_crack_size = nn.Linear(128, num_size_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        # convolutional layer - implementation\n",
        "        x = self.stem(x)\n",
        "\n",
        "        # residual blocks layer - implementation\n",
        "        x = self.layer1a(x)\n",
        "        x = self.layer1b(x)\n",
        "        x = self.layer2a(x)\n",
        "        x = self.layer2b(x)\n",
        "        x = self.layer3a(x)\n",
        "        x = self.layer3b(x)\n",
        "        x = self.layer4a(x)\n",
        "        x = self.layer4b(x)\n",
        "\n",
        "        # pooling and final layer\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.fc_shared(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        fault_detection = self.fc_fault_detection(x)\n",
        "        fault_location = self.fc_fault_location(x)\n",
        "        crack_size = self.fc_crack_size(x)\n",
        "\n",
        "        return fault_detection, fault_location, crack_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krZIsQJdqqeE"
      },
      "source": [
        "### Training Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "resnet_model = ResNet1D_pt()\n",
        "\n",
        "resnet_ctte.load_model(resnet_model)\n",
        "\n",
        "resnet_ctte.load_optimizer(\n",
        "    torch.optim.Adam(resnet_model.parameters(), lr=1e-3)\n",
        ")"
      ],
      "metadata": {
        "id": "CcSY0QY93H00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFEDs3FWqvzU"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_ctte.prepare_data()\n",
        "resnet_ctte.train(epochs=20, batch_size=64)\n",
        "resnet_ctte.evaluate()"
      ],
      "metadata": {
        "id": "dysgR4De3f3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8kYSbSmqxTS"
      },
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_ctte.classification_report()\n"
      ],
      "metadata": {
        "id": "MvPoJ_02e6bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Interpretation\n",
        "\n",
        "ResNet's good performance makes sense due to the architecture's natural fit for vibration signal classification. Vibration signals contain diagnostic information at multiple scales — high-frequency transients from crack impacts, medium-frequency resonance patterns, and longer-range periodic structures from rotating components. The progressive downsampling through residual groups means the network builds up representations at each of these scales, from fine-grained waveform features in early layers to broad structural patterns in deeper ones.\n",
        "\n",
        "The residual connections also help here specifically. Subtle fault signatures can be small perturbations on top of dominant healthy vibration patterns — which is essentially what a residual is. By learning differences from the input rather than full transformations, the network is well-suited to detecting these small but diagnostically meaningful deviations. A healthy signal passes through with near-zero residuals, while a fault introduces learnable differences that propagate through to the classification heads.\n",
        "\n",
        "The multi-head design also plays a role. Because detection, location, and size classification share the same learned feature backbone, the network can exploit correlations between tasks — for instance, certain frequency signatures that indicate a crack also carry information about where it is. This shared learning likely gives better results than training three separate models, especially when data is limited.\n",
        "\n",
        "## Gated Recurrent Unit (GRU)\n",
        "\n",
        "### Model Background and Concept\n",
        "\n",
        "The ResNet1D architecture described above processes a signal by sliding learned filters across it. Each convolutional layer looks at a fixed-width window of the input at a time, and the network builds up longer-range awareness by stacking many such layers and progressively compressing the temporal dimension. The key insight is that every position in the signal is treated somewhat independently; context is gathered implicitly through depth and receptive field growth.\n",
        "\n",
        "Recurrent networks like the GRU we build in this section, and the LSTM in the next, take a fundamentally different approach. Rather than scanning a signal with fixed filters, a series of cells read it sequentially and pass a hidden state that acts as a running memory of everything seen so far.\n",
        "\n",
        "\n",
        "![Recurrent Neural Network GIF](https://miro.medium.com/v2/resize:fit:720/format:webp/1*AQ52bwW55GsJt6HTxPDuMA.gif)\n",
        "\n",
        "Note: *With a univariate time series, the 3x1 input vectors above are actually just 1x1 vectors representing the reading at that point in time.*\n",
        "\n",
        "This \"hidden state\" sounds a lot more mysterious and shadowy than it really is. Like most things in deep learning, it is just a vector. Each cell receives the hidden state passed from the previous cell and updates it to pass to the cell after it. This means later time steps have direct access to a sort of learned compressed memory of steps that came before it - that is the principle that unites recurrent architectures.  However, it is in the updating of a new hidden state where vanilla RNNs, GRUs, and LSTMs differ from each other.\n",
        "\n",
        "A **vanilla RNN** updates the hidden state a simple linear combination of the hidden state and the input value(s). The same set of weights and biases are shared across all cells, so the network learns which values are best to shape the hidden state through the sequence. While this is conceptually clean, it breaks down in practice because the same update rule is applied at every step and gradients decay rapidly as they are propagated back through many time steps, making it very difficult for the network to learn dependencies that span long stretches of the sequence. This is known as the vanishing gradient problem.\n",
        "\n",
        "A **GRU (Gated Recurrent Unit)** adds complexity by introducing two learned gating mechanisms that allow for long term dependencies.\n",
        "![GRU Static](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbRz9BuSgSMqMnSKzSY-dw.png)\n",
        "\n",
        "If the above seems complicated, that's because it is (but just wait for LSTMs!). The animated image below helps us understand the flow.\n",
        "![GRU](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*lNNJOWnMjxLzdUnUQqwKcw.gif)\n",
        "\n",
        "*Source for images is [Raimi Karim](https://medium.com/data-science/animated-rnn-lstm-and-gru-ef124d06cf45), many thanks.*\n",
        "\n",
        "We can understand the steps like this:\n",
        "\n",
        "First, the hidden state and the input are concatenated together to produce a new vector. This concatenated vector is the base input to everything that happens inside the cell.\n",
        "\n",
        "From here, there are two effectively parallel streams, we will call them *reset* and *update*.\n",
        "\n",
        "Reset-1. This concatenated vector is then passed to the *reset gate* and *update gate*, both of which are small fully connected layers that reduce the concatenated vector back down to the length of the hidden state vector, while also applying sigmoid activations (0 to 1) on each output.\n",
        "\n",
        "Reset-2. The reset gate output is then multiplied elementwise with the previous hidden state. The result is a version of the previous hidden state with some values scaled down or zeroed out, which is effectively deciding how much of the old memory is relevant when computing what to write next. That keep and forget pattern is what the fully connected layer in the reset gate aims to learn.\n",
        "\n",
        "Reset-3. The output of step 3, the reset-gated hidden state, is concatenated back onto the original input and sent to another small fully connected layer with a TanH activation function (-1 to 1)\n",
        "\n",
        "For the update path:\n",
        "\n",
        "Update-1. The concatenated vector is also fed into the *update gate*, another small fully connected layer with each output getting a sigmoid activation. This produces another vector of values between 0 and 1, one per hidden state dimension.\n",
        "\n",
        "Update-2. The update gate output controls the final blend between the old hidden state and the candidate new hidden state produced by the reset path. It does this in two parallel multiplications:\n",
        "\n",
        "- The candidate hidden state from Reset-3 is multiplied elementwise by the update gate output z\n",
        "- The original previous hidden state h_t-1 is multiplied elementwise by (1-z)\n",
        "\n",
        "These two results are then added together to produce the new hidden state h_t. Where z is close to 1 for a given dimension, the new candidate content dominates. Where z is close to 0, the old hidden state is carried forward nearly unchanged. This is the core memory mechanism of the GRU — the update gate is learning when to update and when to preserve, for each dimension of the hidden state independently.\n",
        "\n",
        "The new hidden state h_t is the final output of the cell. It is passed forward to the next cell in the sequence as its received hidden state, and after the last cell in the sequence has processed the final time step, this hidden state represents the GRU's compressed memory of the entire input — which is what gets passed to the fully connected layers for classification.\n",
        "\n",
        "> Reminder: With all this mention of passing the hidden state from cell to cell, it would be easy to think that each cell has it's own set weights for its learned reset and update gates, but that is not the case. The reset gate weights and the update gate weights are shared across all cells and learned across all cells. What is happening in a GRU then is more akin to a loop with one set of values going around the loop (the shared/hidden state) and another set of values being injected at the start of each loop, the input at time step x (and also, loop x). This keeps the parameter count manageable regardless of sequence length, a GRU processing a sequence of 1000 steps has exactly the same number of parameters as one processing a sequence of 10 steps.\n",
        "\n",
        "### Model Anatomy\n",
        "\n",
        "The actual implementation of the GRU in Pytorch is quite simple as all of the complex mechanics described above are internal to PyTorch's `GRU` module, which is the first thing we implement in the GRU model class:\n",
        "\n",
        "* `GRU` is the implementation of a single GRU block, where we define the length of a hidden state.\n",
        "* `fc1` & `fc2` are fully connected linear layers that learn the mappings of the GRU output to the classification heads.\n",
        "\n",
        "### Model Definition"
      ],
      "metadata": {
        "id": "BOlZ19kHFddA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU1D_pt(nn.Module):\n",
        "    def __init__(self, input_size=1, seq_len=1200, hidden_size=128, num_location_classes=4, num_size_classes=4):\n",
        "        super(GRU1D_pt, self).__init__()\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # GRU Layer\n",
        "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(hidden_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "\n",
        "        # Output heads\n",
        "        self.fc_fault_detection = nn.Linear(32, 2)\n",
        "        self.fc_fault_location = nn.Linear(32, num_location_classes)\n",
        "        self.fc_crack_size = nn.Linear(32, num_size_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for layer in [self.fc_fault_detection, self.fc_fault_location, self.fc_crack_size]:\n",
        "            nn.init.xavier_uniform_(layer.weight)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape normalization\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(-1)  # (B, T) -> (B, T, 1)\n",
        "        elif x.ndim == 3 and x.shape[1] == 1:\n",
        "            x = x.permute(0, 2, 1)  # (B, 1, T) -> (B, T, 1)\n",
        "\n",
        "        x = x[:, :self.seq_len, :]\n",
        "\n",
        "        # GRU forward\n",
        "        gru_out, _ = self.gru(x)\n",
        "        out = gru_out[:, -1, :]  # Take last time step\n",
        "\n",
        "        # Fully connected layers\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "\n",
        "        # Multi-head outputs\n",
        "        fault_detection = self.fc_fault_detection(out)\n",
        "        fault_location = self.fc_fault_location(out)\n",
        "        crack_size = self.fc_crack_size(out)\n",
        "\n",
        "        return fault_detection, fault_location, crack_size"
      ],
      "metadata": {
        "id": "PqSdlMxdGIkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "gru_model = GRU1D_pt()\n",
        "\n",
        "gru_ctte.load_model(gru_model)\n",
        "\n",
        "gru_ctte.load_optimizer(\n",
        "    torch.optim.Adam(gru_model.parameters(), lr=1e-3)\n",
        ")"
      ],
      "metadata": {
        "id": "Vp3sYpDVGaf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "hzZtBjVVIlnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_ctte.prepare_data()\n",
        "gru_ctte.train(epochs=100, batch_size=64)\n",
        "gru_ctte.evaluate()"
      ],
      "metadata": {
        "id": "fTB90zl7GjXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_ctte.classification_report()"
      ],
      "metadata": {
        "id": "vuT5R7BRIkj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn81_irNsNJZ"
      },
      "source": [
        "## Long Short Term Memory (LSTM) Neural Network\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "\n",
        "* An **LSTM** takes a similar approach but with more machinery. It introduces a separate *cell state* that runs alongside the hidden state as a second memory channel, and uses three gates rather than two to manage it. This additional structure gives the LSTM more expressive control over long-range memory, at the cost of more parameters and slower training. In practice the GRU and LSTM perform similarly on many tasks, and the GRU is often preferred when training efficiency matters.\n",
        "\n",
        "The practical tradeoff between recurrent and convolutional architectures is real. Recurrent networks capture temporal order explicitly and handle variable-length sequences naturally, but the sequential dependency between cells makes them harder to parallelize during training. Convolutional networks are more efficient but require careful architectural design — stacking, downsampling, widening — to build up the same contextual reach that a recurrent network gets more directly.\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U07xDcGo6hfW"
      },
      "outputs": [],
      "source": [
        "class LSTM1D_pt(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sequence_length=1200,\n",
        "                 chunk_size=10,\n",
        "                 hidden_size=128,\n",
        "                 num_layers=3,\n",
        "                 dropout_rate=0.3,\n",
        "                 num_fault_locations=4,\n",
        "                 num_crack_sizes=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.chunk_size = chunk_size\n",
        "        self.num_steps = sequence_length // chunk_size  # 1200/10 = 120 steps\n",
        "\n",
        "        # Input projection: transform each chunk into a richer representation\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(chunk_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "        )\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout_rate,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "\n",
        "        # Attention pooling over timesteps\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Shared FC\n",
        "        self.fc_shared = nn.Linear(hidden_size * 2, 256)\n",
        "\n",
        "        # Output heads — all raw logits\n",
        "        self.fault_detection_output = nn.Linear(256, 2)\n",
        "        self.fault_location_output = nn.Linear(256, num_fault_locations)\n",
        "        self.crack_size_output = nn.Linear(256, num_crack_sizes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Orthogonal init for LSTM (proven to help with long sequences)\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.zeros_(param)\n",
        "                # Set forget gate bias to 1 to encourage remembering\n",
        "                hidden = self.lstm.hidden_size\n",
        "                param.data[hidden:2*hidden].fill_(1.0)\n",
        "\n",
        "        for layer in [self.fc_shared, self.fault_detection_output,\n",
        "                      self.fault_location_output, self.crack_size_output]:\n",
        "            nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, seq_len] or [batch, 1, seq_len]\n",
        "        if x.dim() == 3:\n",
        "            x = x.squeeze(1)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Chunk the signal: [batch, 1200] -> [batch, 120, 10]\n",
        "        x = x.view(batch_size, self.num_steps, self.chunk_size)\n",
        "\n",
        "        # Project each chunk: [batch, 120, 10] -> [batch, 120, hidden_size]\n",
        "        x = self.input_proj(x)\n",
        "\n",
        "        # Bidirectional LSTM: [batch, 120, hidden_size*2]\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Attention pooling: learn which timesteps matter\n",
        "        attn_weights = self.attention(lstm_out)        # [batch, 120, 1]\n",
        "        attn_weights = F.softmax(attn_weights, dim=1)  # [batch, 120, 1]\n",
        "        features = (lstm_out * attn_weights).sum(dim=1) # [batch, hidden_size*2]\n",
        "\n",
        "        features = self.layer_norm(features)\n",
        "        features = self.dropout(F.relu(self.fc_shared(features)))\n",
        "\n",
        "        fault_detection = self.fault_detection_output(features)\n",
        "        fault_location = self.fault_location_output(features)\n",
        "        crack_size = self.crack_size_output(features)\n",
        "\n",
        "        return fault_detection, fault_location, crack_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qvTHho56hfW"
      },
      "outputs": [],
      "source": [
        "lstm_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "lstm_model = LSTM1D_pt(\n",
        "    sequence_length=1200,\n",
        "    hidden_size=128,\n",
        "    num_layers=2,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "lstm_ctte.load_model(lstm_model)\n",
        "\n",
        "lstm_ctte.load_optimizer(\n",
        "    torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut3rlFxx6hfW"
      },
      "outputs": [],
      "source": [
        "lstm_ctte.prepare_data()\n",
        "lstm_ctte.train(epochs=20, batch_size=64)\n",
        "lstm_ctte.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juPVfhZY6hfW"
      },
      "outputs": [],
      "source": [
        "lstm_ctte.classification_report()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}