{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwhitz/ts-trove/blob/master/notebooks/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVkS8EnJ6hfS"
      },
      "source": [
        "# Time Series Classification\n",
        "\n",
        "This notebook explores various time series classification techniques. It makes much fuller use of the bearings dataset also explored in the signal analysis notebook.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Time series classification involves assigning time series instances to predefined categories. This notebook will cover:\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "> 1 [Data Preparation](#Data-Preparation)\n",
        "\n",
        "1.1. [Data Download](##Data-Download)\n",
        "\n",
        "1.2 [Data Organization](##Data-Organization)\n",
        "\n",
        "> 2 [Utility Functions](#Training-Functions)\n",
        "\n",
        "2.1 [Data Loader](##Data-Loader)\n",
        "\n",
        "> 3 [Time Series Classification with SciKit](#Scikit-Functions)\n",
        "\n",
        "3.1 [Scikit Trainer and Evaluator](##Scikit-Trainer-and-Evaluator)\n",
        "\n",
        "> 4 [Deep Learning Models](#Deep-Learning-Models)\n",
        "\n",
        "4.1 [PyTorch Trainer and Evaluator](##-Trainer-and-Evaluator)\n",
        "\n",
        "4.2 [Fully Connected Neural Networks]()\n",
        "\n",
        "4.3 [Recurrent Neural Networks]()\n",
        "\n",
        "4.3.1 [Classic Recurrent Neural Network]()\n",
        "\n",
        "4.3.2 [Long Short Term Memory (LSTM) Neural Network]()\n",
        "\n",
        "4.3.3 [Gated Recurrent Neural Network]()\n",
        "\n",
        "4.4 [Convolutional Neural Networks]()\n",
        "\n",
        "4.4.1 [1D Convolutional Neural Network]()\n",
        "\n",
        "4.4.2 [Temporal Convolutional Network]()\n",
        "\n",
        "4.5 [Attention Based Models]()\n",
        "\n",
        "4.5.1 [LSTM with Attention]()\n",
        "\n",
        "4.5.2 [Time Series Transformer]()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MKXciZyo6hfT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pathlib\n",
        "import shutil\n",
        "import kagglehub\n",
        "\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cesium"
      ],
      "metadata": {
        "id": "Cs3qdujLVjZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3e446e-15ba-4f6f-9dda-2d5d7ef7823c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cesium in /usr/local/lib/python3.12/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from cesium) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from cesium) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.12/dist-packages (from cesium) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from cesium) (2.2.2)\n",
            "Requirement already satisfied: dask>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cesium) (2025.12.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from cesium) (0.12.1)\n",
            "Requirement already satisfied: gatspy>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from cesium) (0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from cesium) (3.1.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from cesium) (1.5.3)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.5.0->cesium) (8.3.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.5.0->cesium) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.5.0->cesium) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.5.0->cesium) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.5.0->cesium) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.17.0->cesium) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.17.0->cesium) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.17.0->cesium) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.1->cesium) (3.6.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask>=2.5.0->cesium) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.17.0->cesium) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "## Data Overview\n",
        "\n",
        "**What is this dataset?**\n",
        "\n",
        "This is a collection of vibration data from electric motor bearings. Bearings those small spinning parts that let machinery rotate smoothly. Think of a bearing like the axle in a wheel: it's got little metal balls inside that roll around, letting a shaft spin with barely any friction.\n",
        "\n",
        "**Why was this dataset created?**\n",
        "\n",
        "The researchers at Case Western Reserve University deliberately damaged bearings in different ways, then recorded how the motor vibrated as a result. They made tiny cracks of various sizes (ranging from 7 to 40 thousandths of an inch) in the bearings, then attached vibration sensors to measure what happened.\n",
        "\n",
        "Cracks of different mm sizes were introduced on the outer race, inner race, and the balls themselves.\n",
        "\n",
        "![ball_bearing_diagram](https://www.globalspec.com/ImageRepository/LearnMore/20133/ball%20bearing5364b00280ef4db7b85dfba113f04556.png)\n",
        "\n",
        "The goal was to understand the relationship between bearing damage and vibration patterns, creating a reference library that shows what different types of bearing failure look like.\n",
        "\n",
        "**Why is it useful?**\n",
        "\n",
        "This data is incredibly useful for real-world maintenance and diagnostics. In factories and power plants, you can use vibration patterns to detect bearing problems before they cause catastrophic failures. By comparing vibrations from a running machine to patterns in this dataset, maintenance teams can identify early signs of wear, predict when a bearing will fail, and schedule repairs before expensive downtime happens. It's basically like a fingerprint database for bearing damage—once you know what a damaged bearing \"sounds like,\" you can spot trouble coming.\n",
        "\n",
        "**So what are we actually trying to predict?**\n",
        "\n",
        "Good question. We will try to train machine learning models to predict three things: 1) Is the bearing in normal operation? 2) If not, where is the crack? 3) And what size is it?\n",
        "\n",
        "2 and 3 of course become irrelevant if the bearing is in normal operation, but they allow us to go a step beyond simple detection of irregular operation.\n",
        "\n",
        "\n",
        "## Data Download\n",
        "\n",
        "The raw data can be downloaded directly from Kaggle."
      ],
      "metadata": {
        "id": "jlDAmb6rUOA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kagglepath = \"sufian79/cwru-mat-full-dataset\"\n",
        "path = kagglehub.dataset_download(kagglepath)\n",
        "\n",
        "\n",
        "pathlib.Path(f\"./{kagglepath.split('/')[-1]}\").mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, f\"./{kagglepath.split('/')[-1]}\", dirs_exist_ok=True)"
      ],
      "metadata": {
        "id": "ak_iKkQdUCfF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3ce9bf5b-abf8-44ff-fb81-38a7e047e0eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'cwru-mat-full-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./cwru-mat-full-dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Organization\n",
        "\n",
        "The raw data is a collection of numbered mat files and requires reference back to the [original website](https://engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data) to make sense of. I've gone ahead and done that with the JSON structure below.\n",
        "\n",
        "The data is organized at top-level describing the type of fault, or lack thereof with \"normal\" sample files are the motor operating without faults. The next level down is the sampling rate, followed by the location where the crack was introduced (IR being inner race, B being ball, OR being outer race) and then finally, the size of the cracks ranging from 7 to 21 mm.\n",
        "\n",
        "The code below this cell moves the individual samples into folders matching the structure below, which aligns with how PyTorch's DataSet and DataLoader work (we will make it work for scikit too)."
      ],
      "metadata": {
        "id": "ZvtGS34aluAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_structure = {\n",
        "  \"normal\": {\n",
        "    \"48k\": [\"97\", \"98\", \"99\", \"100\"]\n",
        "  },\n",
        "  \"drive_end_fault\": {\n",
        "    \"12k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"105\", \"106\", \"107\", \"108\"],\n",
        "        \"014\": [\"169\", \"170\", \"171\", \"172\"],\n",
        "        \"021\": [\"209\", \"210\", \"211\", \"212\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"118\", \"119\", \"120\", \"121\"],\n",
        "        \"014\": [\"185\", \"186\", \"187\", \"188\"],\n",
        "        \"021\": [\"222\", \"223\", \"224\", \"225\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"130\", \"131\", \"132\", \"133\"],\n",
        "        \"014\": [\"197\", \"198\", \"199\", \"200\"],\n",
        "        \"021\": [\"234\", \"235\", \"236\", \"237\"]\n",
        "      }\n",
        "    },\n",
        "\n",
        "    \"48k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"109\", \"110\", \"111\", \"112\"],\n",
        "        \"014\": [\"174\", \"175\", \"176\", \"177\"],\n",
        "        \"021\": [\"213\", \"214\", \"215\", \"217\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"122\", \"123\", \"124\", \"125\"],\n",
        "        \"014\": [\"189\", \"190\", \"191\", \"192\"],\n",
        "        \"021\": [\"226\", \"227\", \"228\", \"229\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"135\", \"136\", \"137\", \"138\"],\n",
        "        \"014\": [\"201\", \"202\", \"203\", \"204\"],\n",
        "        \"021\": [\"238\", \"239\", \"240\", \"241\"]\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "\n",
        "  \"fan_end_fault\": {\n",
        "    \"12k\": {\n",
        "      \"IR\": {\n",
        "        \"007\": [\"278\", \"279\", \"280\", \"281\"],\n",
        "        \"014\": [\"274\", \"275\", \"276\", \"277\"],\n",
        "        \"021\": [\"270\", \"271\", \"272\", \"273\"]\n",
        "      },\n",
        "\n",
        "      \"B\": {\n",
        "        \"007\": [\"282\", \"283\", \"284\", \"285\"],\n",
        "        \"014\": [\"286\", \"287\", \"288\", \"289\"],\n",
        "        \"021\": [\"290\", \"291\", \"292\", \"293\"]\n",
        "      },\n",
        "\n",
        "      \"OR\": {\n",
        "        \"007\": [\"298\", \"299\", \"300\", \"301\"],\n",
        "        \"014\": [\"309\", \"310\", \"311\", \"312\"],\n",
        "        \"021\": [\"315\", \"316\", \"317\", \"318\"]\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "fe1oXdcK2h1E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_DIR = \"cwru-mat-full-dataset/\"\n",
        "TARGET_DIR = \"classification-cwru-mat-organized\"\n",
        "FILE_EXTENSION = \".mat\"\n",
        "\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def move_file(file_id, dest_dir):\n",
        "    filename = file_id + FILE_EXTENSION\n",
        "    src_path = os.path.join(SOURCE_DIR, filename)\n",
        "    dst_path = os.path.join(dest_dir, filename)\n",
        "\n",
        "    if not os.path.exists(src_path):\n",
        "        print(f\"⚠️ Missing file: {src_path}\")\n",
        "        return\n",
        "\n",
        "    ensure_dir(dest_dir)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "def walk_structure(node, current_path):\n",
        "    if isinstance(node, list):\n",
        "        for file_id in node:\n",
        "            move_file(file_id, current_path)\n",
        "    elif isinstance(node, dict):\n",
        "        for key, child in node.items():\n",
        "            walk_structure(child, os.path.join(current_path, key))\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected structure type\")\n",
        "\n",
        "\n",
        "walk_structure(folder_structure, TARGET_DIR)\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "XUY9UIluUtx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8348163f-e9f0-40e8-9d07-7d26330712a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59mefCkU6hfU"
      },
      "source": [
        "# Utility Functions\n",
        "\n",
        "## Data Loader\n",
        "\n",
        "Before diving into modeling, we first need a consistent way to load and represent our time-series data. Since later sections will experiment with both deep learning and traditional classifiers, we define a reusable dataset structure that keeps preprocessing, sampling rate handling, and labels consistent across all methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "N9S8fo-16hfU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn import Module\n",
        "import scipy.io\n",
        "import enum\n",
        "\n",
        "# samplng rate enum\n",
        "class SamplingRate(enum.Enum):\n",
        "    sr12K = \"12k\"\n",
        "    sr48K = \"48k\"\n",
        "\n",
        "class FaultLocation(enum.Enum):\n",
        "    DE = \"drive_end_fault\"\n",
        "    FE = \"front_end_fault\"\n",
        "\n",
        "\n",
        "class BearingDataset(Dataset):\n",
        "    def __init__(self, file_paths, sampling_rate, fault_location, chunk_length, unified_label=True, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.fault_location = fault_location\n",
        "        self.chunk_length = chunk_length\n",
        "        self.transform = transform\n",
        "        self.unified_label = unified_label\n",
        "\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        self._organize_data()\n",
        "\n",
        "    def _organize_data(self):\n",
        "        for fp in self.file_paths:\n",
        "            if not pathlib.Path(fp).exists():\n",
        "                raise FileNotFoundError(f\"File not found: {fp}\")\n",
        "\n",
        "            mat_data = scipy.io.loadmat(fp)\n",
        "\n",
        "            key_to_match = f\"_{str(self.fault_location)[-2:]}_time\"\n",
        "            sensor_key = [key for key in mat_data.keys() if key_to_match in key][0]\n",
        "\n",
        "            signal = mat_data[sensor_key].squeeze()\n",
        "\n",
        "            n_chunks = len(signal) // self.chunk_length\n",
        "            truncated = signal[:n_chunks * self.chunk_length]\n",
        "\n",
        "            windows = truncated.reshape(n_chunks, self.chunk_length)\n",
        "\n",
        "            label_parts = fp.parent.parts\n",
        "            if label_parts[-2] == 'normal':\n",
        "                label_dict = {\n",
        "                    'normal': True,\n",
        "                    'fault_location': 'NA',\n",
        "                    'crack_size': 'NA'\n",
        "                }\n",
        "            else:\n",
        "                label_dict = {\n",
        "                    'normal': False,\n",
        "                    'fault_location': label_parts[-2],\n",
        "                    'crack_size': label_parts[-1]\n",
        "                }\n",
        "\n",
        "\n",
        "            for window in windows:\n",
        "              self.data.append(window)\n",
        "\n",
        "              if self.unified_label:\n",
        "                self.labels.append(f\"{label_dict['fault_location']}_{label_dict['crack_size']}\" if label_dict['normal'] == False else \"normal\")\n",
        "              else:\n",
        "                self.labels.append(label_dict)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        window = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            window = self.transform(window).astype('float32')\n",
        "\n",
        "        return window, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkVWvbwf6hfU"
      },
      "source": [
        "The dataset class above seeks to make the most of the data available in the bearings dataset by splitting each sample in the file into multiple overlapping windows. This increases the effective number of training samples and helps models learn more robust patterns. However, care must be taken to avoid data leakage between training and test sets when using overlapping windows - if we were to pull all the data and then split into train/test, windows from the same original sample could end up in both sets.\n",
        "\n",
        "To prevent this, we ensure that all windows derived from a given file are assigned to either the training or test set exclusively by splitting into train/test at the file level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2etv3hUJ6hfV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "all_files = list(Path(\"classification-cwru-mat-organized\").rglob(\"*.mat\"))\n",
        "\n",
        "# derive one label per file\n",
        "file_labels = [\n",
        "    '_'.join(f.parent.parts[-2:])\n",
        "    for f in all_files\n",
        "]\n",
        "\n",
        "train_files, test_files = train_test_split(\n",
        "    all_files,\n",
        "    test_size=.2,\n",
        "    shuffle=True,\n",
        "    stratify=file_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rekM3G0s6hfV"
      },
      "source": [
        "##\n",
        "\n",
        "We want to set up a class for testing different classification techniques on the bearings dataset. The class will accept a dataset object and classification model, and be able to train and evaluate the model consistently for metrics like accuracy, precision, recall, and F1-score as well as time for training and inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6Zq-Isg86hfV"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "\n",
        "class ClassificationTrainTestEvaluate(ABC):\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def classification_report(self):\n",
        "      \"\"\"\n",
        "      Creates a Plotly figure with three tabs, each showing:\n",
        "      - Confusion matrix heatmap\n",
        "      - Metrics summary table\n",
        "\n",
        "      One tab per task: Fault Detection, Fault Location, Crack Size\n",
        "      \"\"\"\n",
        "      from plotly.subplots import make_subplots\n",
        "      import plotly.graph_objects as go\n",
        "      from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "      # Define task names and their corresponding predictions/labels\n",
        "      tasks = {\n",
        "          'Fault Detection': {\n",
        "              'predictions': self.predictions_fault_detection,\n",
        "              'labels': self.test_y_fault_detection,\n",
        "              'class_names': ['Normal', 'Fault']\n",
        "          },\n",
        "          'Fault Location': {\n",
        "              'predictions': self.predictions_fault_location,\n",
        "              'labels': self.test_y_fault_location,\n",
        "              'class_names': ['B', 'IR', 'OR']\n",
        "          },\n",
        "          'Crack Size': {\n",
        "              'predictions': self.predictions_crack_size,\n",
        "              'labels': self.test_y_crack_size,\n",
        "              'class_names': ['007', '014', '021']\n",
        "          }\n",
        "      }\n",
        "\n",
        "      # Create subplots for each task\n",
        "      figs = []\n",
        "\n",
        "      for task_name, task_data in tasks.items():\n",
        "          predictions = task_data['predictions']\n",
        "          labels = task_data['labels']\n",
        "          class_names = task_data['class_names']\n",
        "\n",
        "          # Compute confusion matrix\n",
        "          cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "          # Compute metrics\n",
        "          accuracy = accuracy_score(labels, predictions)\n",
        "          precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
        "          recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
        "          f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "          # Create subplot layout\n",
        "          fig = make_subplots(\n",
        "              rows=1, cols=2,\n",
        "              column_widths=[0.6, 0.4],\n",
        "              specs=[[{\"type\": \"heatmap\"}, {\"type\": \"table\"}]],\n",
        "              subplot_titles=(\"Confusion Matrix\", \"Model Performance Metrics\")\n",
        "          )\n",
        "\n",
        "          # --- Confusion Matrix Heatmap ---\n",
        "          fig.add_trace(\n",
        "              go.Heatmap(\n",
        "                  z=cm,\n",
        "                  x=class_names,\n",
        "                  y=class_names,\n",
        "                  text=cm,\n",
        "                  texttemplate=\"%{text}\",\n",
        "                  colorscale=\"Blues\",\n",
        "                  showscale=False\n",
        "              ),\n",
        "              row=1, col=1\n",
        "          )\n",
        "\n",
        "          fig.update_xaxes(title_text=\"Predicted Label\", row=1, col=1)\n",
        "          fig.update_yaxes(title_text=\"True Label\", row=1, col=1)\n",
        "\n",
        "          # --- Metrics Table ---\n",
        "          fig.add_trace(\n",
        "              go.Table(\n",
        "                  header=dict(\n",
        "                      values=[\"Metric\", \"Value\"],\n",
        "                      fill_color=\"lightgrey\",\n",
        "                      align=\"center\"\n",
        "                  ),\n",
        "                  cells=dict(\n",
        "                      values=[\n",
        "                          [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
        "                          [f\"{accuracy:.4f}\", f\"{precision:.4f}\", f\"{recall:.4f}\", f\"{f1:.4f}\"]\n",
        "                      ],\n",
        "                      align=\"center\"\n",
        "                  )\n",
        "              ),\n",
        "              row=1, col=2\n",
        "          )\n",
        "\n",
        "          fig.update_layout(\n",
        "              title=f\"{task_name} - Evaluation Summary\",\n",
        "              height=500,\n",
        "              width=900,\n",
        "              showlegend=False\n",
        "          )\n",
        "\n",
        "          figs.append((task_name, fig))\n",
        "\n",
        "      # Display each figure\n",
        "      for task_name, fig in figs:\n",
        "          fig.show()\n",
        "\n",
        "class SciKitCTTE(ClassificationTrainTestEvaluate):\n",
        "    def prepare_data(self):\n",
        "        self.train_X, self.train_y = pd.DataFrame(), pd.Series()\n",
        "        print(\"Preparing training data...\")\n",
        "        for i in tqdm(range(len(self.train_dataset))):\n",
        "            X_chunk, label = self.train_dataset[i]\n",
        "\n",
        "            self.train_X = pd.concat([self.train_X, X_chunk], ignore_index=True)\n",
        "            self.train_y = pd.concat([self.train_y, pd.Series(label)], ignore_index=True)\n",
        "\n",
        "        self.test_X, self.test_y = pd.DataFrame(), pd.Series()\n",
        "        print(\"Preparing test data...\")\n",
        "        for i in tqdm(range(len(self.test_dataset))):\n",
        "            X_chunk, labels = self.test_dataset[i]\n",
        "\n",
        "            self.test_X = pd.concat([self.test_X, X_chunk], ignore_index=True)\n",
        "            self.test_y = pd.concat([self.test_y, pd.Series(labels)], ignore_index=True)\n",
        "\n",
        "    def train(self, train_X, train_y):\n",
        "        self.model.fit(train_X, train_y)\n",
        "        self.class_names = sorted(self.train_y.unique())\n",
        "\n",
        "    def evaluate(self, test_X, test_y):\n",
        "        self.predictions = self.model.predict(test_X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNl5Ed836hfV"
      },
      "source": [
        "# Feature Extraction + Feature Based Classification\n",
        "\n",
        "With a dataset abstraction in place, we can now explore different families of time-series classification techniques. The goal here is not only to compare performance, but also to understand how different representation choices affect model behavior on sensor-like signals.\n",
        "\n",
        "We begin with feature-based methods, which transform raw time-series into fixed-length statistical representations. These approaches are often strong baselines, easier to interpret, and computationally efficient compared to end-to-end deep learning models.\n",
        "\n",
        "### Feature Extraction\n",
        "\n",
        "We will implement a custom transformer class for the PyTorch dataset to extract statistical features using the `cesium` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yZLiYT5C6hfV"
      },
      "outputs": [],
      "source": [
        "from cesium import featurize\n",
        "\n",
        "class FeatureExtractionTransform(Module):\n",
        "    def forward(self, window):\n",
        "        features_to_use = [\n",
        "            \"amplitude\",\n",
        "            \"percent_beyond_1_std\",\n",
        "            \"maximum\",\n",
        "            \"max_slope\",\n",
        "            \"median\",\n",
        "            \"median_absolute_deviation\",\n",
        "            \"percent_close_to_median\",\n",
        "            \"minimum\",\n",
        "            \"period_fast\",\n",
        "            \"skew\",\n",
        "            \"std\",\n",
        "        ]\n",
        "\n",
        "        fset = featurize.featurize_time_series(\n",
        "            times=np.arange(len(window)),\n",
        "            values=window,\n",
        "            errors=None,\n",
        "            features_to_use=features_to_use,\n",
        "        )\n",
        "\n",
        "        fset = fset.stack(future_stack=True)\n",
        "\n",
        "        return fset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZHK6_RwQ6hfW"
      },
      "outputs": [],
      "source": [
        "train_dataset = BearingDataset(\n",
        "    train_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    chunk_length=1200,\n",
        "    unified_label=True,\n",
        "    transform=FeatureExtractionTransform()\n",
        ")\n",
        "\n",
        "test_dataset = BearingDataset(\n",
        "    test_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    chunk_length=1200,\n",
        "    unified_label=True,\n",
        "    transform=FeatureExtractionTransform()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XZbEHq_n6hfW"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# sk_ctte = SciKitCTTE(\n",
        "#     train_dataset,\n",
        "#     test_dataset)\n",
        "\n",
        "# sk_ctte.prepare_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rfc = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "\n",
        "# sk_trainer = sk_ctte\n",
        "# sk_trainer.load_model(rfc)\n",
        "\n",
        "# sk_trainer.train(sk_trainer.train_X, sk_trainer.train_y)\n",
        "# sk_trainer.evaluate(sk_trainer.test_X, sk_trainer.test_y)\n",
        "# sk_trainer.classification_report()"
      ],
      "metadata": {
        "id": "QyKA2bPqXwU1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm = SVC(kernel='linear', C=.1, random_state=42)\n",
        "\n",
        "# sk_trainer = sk_ctte\n",
        "# sk_trainer.load_model(svm)\n",
        "\n",
        "# sk_trainer.train(sk_trainer.train_X, sk_trainer.train_y)\n",
        "# sk_trainer.evaluate(sk_trainer.test_X, sk_trainer.test_y)\n",
        "# sk_trainer.classification_report()"
      ],
      "metadata": {
        "id": "6Wq0vPwDYPDv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6j9W0Qc6hfW"
      },
      "source": [
        "# Deep Learning Models\n",
        "\n",
        "In this section, I will explore a wide variety of neural network models to find which can perform the best at what is essentially a many-to-one problem, where we are giving the model a dataset of many measurements of vibrational movement where ordering matters, because those measurements unfolded across time.\n",
        "\n",
        "4.1 [PyTorch Trainer and Evaluator](##\n",
        "PyTorch-Trainer-and-Evaluator)\n",
        "\n",
        "4.2 [Fully Connected Neural Networks]()\n",
        "\n",
        "4.3 [Recurrent Neural Networks]()\n",
        "\n",
        "4.3.1 [Classic Recurrent Neural Network]()\n",
        "\n",
        "4.3.2 [Long Short Term Memory (LSTM) Neural Network]()\n",
        "\n",
        "4.3.3 [Gated Recurrent Neural Network]()\n",
        "\n",
        "4.4 [Convolutional Neural Networks]()\n",
        "\n",
        "4.4.1 [1D Convolutional Neural Network]()\n",
        "\n",
        "4.4.2 [Temporal Convolutional Network]()\n",
        "\n",
        "4.5 [Attention Based Models]()\n",
        "\n",
        "4.5.1 [LSTM with Attention]()\n",
        "\n",
        "4.5.2 [Time Series Transformer]()\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vnJFPo3RWk0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b501a248-ffa6-4c5e-e41f-26a06165967e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n",
            "GPU count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PyTorch Trainer and Evaluator"
      ],
      "metadata": {
        "id": "Aaqrd4QTsE8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qznbgXrq6hfW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch import Tensor, float32, LongTensor\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "class PyTorchCTTE(ClassificationTrainTestEvaluate):\n",
        "    def __init__(self, train_dataset: Dataset, test_dataset: Dataset, device='cpu', criterion=None):\n",
        "        super().__init__(train_dataset, test_dataset)\n",
        "        self.device = device\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.target_mapping = {\n",
        "          'fault_location': {'B': 0, 'IR': 1, 'OR': 2, 'NA': 3},\n",
        "          'crack_size': {'007': 0, '014': 1, '021': 2, 'NA': 3}\n",
        "          }\n",
        "\n",
        "        self.train_dataset_mean = None\n",
        "        self.train_dataset_std = None\n",
        "\n",
        "    def __deepcopy__(self, memo):\n",
        "        \"\"\"Deep copy - recursively copies nested objects\"\"\"\n",
        "        return PyTorchCTTE(\n",
        "            copy.deepcopy(self.train_dataset, memo),\n",
        "            copy.deepcopy(self.test_dataset, memo),\n",
        "            copy.deepcopy(self.device, memo),\n",
        "            copy.deepcopy(self.criterion, memo)\n",
        "        )\n",
        "\n",
        "    def load_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def load_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=64, shuffle=True)\n",
        "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    def train(self, epochs: int, batch_size: int):\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.train_dataset_mean = np.mean(np.concatenate(self.train_dataset.data))\n",
        "        self.train_dataset_std = np.std(np.concatenate(self.train_dataset.data))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            progress_bar = tqdm(self.train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "            for batch_X, batch_y in progress_bar:\n",
        "                # X\n",
        "                batch_X = (Tensor(batch_X.to(float32)) - self.train_dataset_mean) / self.train_dataset_std\n",
        "                batch_X = batch_X.to(self.device)\n",
        "\n",
        "                # ys\n",
        "                batch_y_fault_detection = [int(l) for l in batch_y['normal']]\n",
        "                batch_y_fault_location = [self.target_mapping['fault_location'].get(l, 2) for l in batch_y['fault_location']]\n",
        "                batch_y_crack_size = [self.target_mapping['crack_size'].get(l, 2) for l in batch_y['crack_size']]\n",
        "\n",
        "                # move to GPU\n",
        "                batch_y_fault_detection = LongTensor(batch_y_fault_detection).to(self.device)\n",
        "                batch_y_fault_location = LongTensor(batch_y_fault_location).to(self.device)\n",
        "                batch_y_crack_size = LongTensor(batch_y_crack_size).to(self.device)\n",
        "\n",
        "                # clear gradients before training\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # run the inputs through the network\n",
        "                fault_detection, fault_location, crack_size = self.model(batch_X)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss_fault_detection = self.criterion(fault_detection, batch_y_fault_detection)\n",
        "                loss_fault_location = self.criterion(fault_location, batch_y_fault_location)\n",
        "                loss_crack_size = self.criterion(crack_size, batch_y_crack_size)\n",
        "\n",
        "                # sum to total loss\n",
        "                total_loss = loss_fault_detection + loss_fault_location + loss_crack_size\n",
        "\n",
        "                # backpropagate\n",
        "                total_loss.backward()\n",
        "\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += total_loss.item()\n",
        "                progress_bar.set_postfix(loss=total_loss.item())\n",
        "\n",
        "            print(f\"Epoch {epoch+1} avg loss: {epoch_loss/len(self.train_dataloader):.4f}\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        self.predictions_fault_detection = []\n",
        "        self.predictions_fault_location = []\n",
        "        self.predictions_crack_size = []\n",
        "        self.test_y_fault_detection = []\n",
        "        self.test_y_fault_location = []\n",
        "        self.test_y_crack_size = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in self.test_dataloader:\n",
        "                batch_X = (Tensor(batch_X).to(float32) - self.train_dataset_mean) / self.train_dataset_std\n",
        "                batch_X = batch_X.to(self.device)\n",
        "\n",
        "                fault_detection, fault_location, crack_size = self.model(batch_X)\n",
        "\n",
        "                # Get predictions for each task\n",
        "                _, pred_fd = torch.max(fault_detection, 1)\n",
        "                _, pred_fl = torch.max(fault_location, 1)\n",
        "                _, pred_cs = torch.max(crack_size, 1)\n",
        "\n",
        "                self.predictions_fault_detection.extend(pred_fd.cpu().numpy().tolist())\n",
        "                self.predictions_fault_location.extend(pred_fl.cpu().numpy().tolist())\n",
        "                self.predictions_crack_size.extend(pred_cs.cpu().numpy().tolist())\n",
        "\n",
        "                # Store true labels\n",
        "                self.test_y_fault_detection.extend([int(l) for l in batch_y['normal']])\n",
        "                self.test_y_fault_location.extend([self.target_mapping['fault_location'].get(l, 0) for l in batch_y['fault_location']])\n",
        "                self.test_y_crack_size.extend([self.target_mapping['crack_size'].get(l, 0) for l in batch_y['crack_size']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets for Deep Learning"
      ],
      "metadata": {
        "id": "0i5zcQ8IoQZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import cross entropy loss\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "train_dataset = BearingDataset(\n",
        "    train_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    unified_label=False,\n",
        "    chunk_length=1200\n",
        ")\n",
        "\n",
        "test_dataset = BearingDataset(\n",
        "    test_files,\n",
        "    sampling_rate=SamplingRate.sr48K,\n",
        "    fault_location=FaultLocation.DE,\n",
        "    unified_label=False,\n",
        "    chunk_length=1200\n",
        ")\n",
        "\n",
        "pytorch_ctte = PyTorchCTTE(\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    device=device,\n",
        "    criterion=CrossEntropyLoss()\n",
        ")"
      ],
      "metadata": {
        "id": "2Xy3Y3G6oTA7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fully Connected Neural Network\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "\n",
        "### Model Definition"
      ],
      "metadata": {
        "id": "aatdzOAusiOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class FCNN(nn.Module):\n",
        "    def __init__(self, input_dim=1200, num_fault_locations=4, num_crack_sizes=4):\n",
        "        super(FCNN, self).__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fault_detection_output = nn.Linear(256, 2)\n",
        "        self.fault_location_output = nn.Linear(256, num_fault_locations)\n",
        "        self.crack_size_output = nn.Linear(256, num_crack_sizes)\n",
        "\n",
        "        # Xavier initialization\n",
        "        nn.init.xavier_uniform_(self.fault_detection_output.weight)\n",
        "        nn.init.xavier_uniform_(self.fault_location_output.weight)\n",
        "        nn.init.xavier_uniform_(self.crack_size_output.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shared(x)\n",
        "\n",
        "        return (\n",
        "            torch.sigmoid(self.fault_detection_output(x)),\n",
        "            self.fault_location_output(x),\n",
        "            self.crack_size_output(x)\n",
        "        )"
      ],
      "metadata": {
        "id": "6xjrzpaqsdZO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fcnn_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "fcnn_model = FCNN(\n",
        "    input_dim=1200\n",
        ")\n",
        "\n",
        "fcnn_ctte.load_model(fcnn_model)\n",
        "\n",
        "fcnn_ctte.load_optimizer(\n",
        "    torch.optim.Adam(fcnn_model.parameters(), lr=1e-3)\n",
        ")\n"
      ],
      "metadata": {
        "id": "bzTD3su0oKQ3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "cHeN777EqEW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcnn_ctte.prepare_data()\n",
        "fcnn_ctte.train(epochs=20, batch_size=64)\n",
        "fcnn_ctte.evaluate()"
      ],
      "metadata": {
        "id": "3Kqr201ko55J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1cadf3-4597-423f-f4ec-04cedf5eded5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 285/285 [00:04<00:00, 63.95it/s, loss=1.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 avg loss: 2.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 285/285 [00:04<00:00, 58.54it/s, loss=1.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 avg loss: 1.3136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 285/285 [00:04<00:00, 58.57it/s, loss=0.912]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 avg loss: 0.9751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 285/285 [00:04<00:00, 62.94it/s, loss=0.656]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 avg loss: 0.7585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 285/285 [00:05<00:00, 53.61it/s, loss=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 avg loss: 0.6220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 285/285 [00:04<00:00, 62.55it/s, loss=0.502]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 avg loss: 0.5268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 285/285 [00:04<00:00, 61.44it/s, loss=0.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 avg loss: 0.4757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 285/285 [00:05<00:00, 52.90it/s, loss=0.411]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 avg loss: 0.4189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 285/285 [00:04<00:00, 61.78it/s, loss=0.534]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 avg loss: 0.4331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 285/285 [00:04<00:00, 58.25it/s, loss=0.465]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 avg loss: 0.4528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 285/285 [00:05<00:00, 53.85it/s, loss=0.347]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 avg loss: 0.3926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 285/285 [00:04<00:00, 60.62it/s, loss=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 avg loss: 0.3914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 285/285 [00:05<00:00, 53.71it/s, loss=0.326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 avg loss: 0.3844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 285/285 [00:05<00:00, 56.88it/s, loss=0.429]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 avg loss: 0.4133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 285/285 [00:05<00:00, 50.14it/s, loss=0.346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 avg loss: 0.3987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 285/285 [00:05<00:00, 50.82it/s, loss=0.357]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 avg loss: 0.3785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 285/285 [00:04<00:00, 59.83it/s, loss=0.321]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 avg loss: 0.3622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 285/285 [00:05<00:00, 53.19it/s, loss=0.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 avg loss: 0.3818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 285/285 [00:07<00:00, 40.12it/s, loss=0.421]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 avg loss: 0.4022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 285/285 [00:09<00:00, 31.53it/s, loss=0.354]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 avg loss: 0.3754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "_df6kHjbp-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcnn_ctte.classification_report()"
      ],
      "metadata": {
        "id": "8FiqW9iap3kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c924d8b-a7e2-4e80-80d3-d6136ddeeaf2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1a2640e3-4c5f-408d-a2d4-e6f7ebbcf252\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1a2640e3-4c5f-408d-a2d4-e6f7ebbcf252\")) {                    Plotly.newPlot(                        \"1a2640e3-4c5f-408d-a2d4-e6f7ebbcf252\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"showscale\":false,\"text\":[[2678,0],[0,403]],\"texttemplate\":\"%{text}\",\"x\":[\"Normal\",\"Fault\"],\"y\":[\"Normal\",\"Fault\"],\"z\":[[2678,0],[0,403]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"cells\":{\"align\":\"center\",\"values\":[[\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"],[\"1.0000\",\"1.0000\",\"1.0000\",\"1.0000\"]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"lightgrey\"},\"values\":[\"Metric\",\"Value\"]},\"type\":\"table\",\"domain\":{\"x\":[0.64,1.0],\"y\":[0.0,1.0]}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.54],\"title\":{\"text\":\"Predicted Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Label\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Confusion Matrix\",\"x\":0.27,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Performance Metrics\",\"x\":0.8200000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Fault Detection - Evaluation Summary\"},\"height\":500,\"width\":900,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1a2640e3-4c5f-408d-a2d4-e6f7ebbcf252');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b4244415-458a-4cea-be4b-b1f38b6093b4\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4244415-458a-4cea-be4b-b1f38b6093b4\")) {                    Plotly.newPlot(                        \"b4244415-458a-4cea-be4b-b1f38b6093b4\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"showscale\":false,\"text\":[[375,14,214,0],[214,283,262,0],[297,89,930,0],[0,0,0,403]],\"texttemplate\":\"%{text}\",\"x\":[\"B\",\"IR\",\"OR\"],\"y\":[\"B\",\"IR\",\"OR\"],\"z\":[[375,14,214,0],[214,283,262,0],[297,89,930,0],[0,0,0,403]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"cells\":{\"align\":\"center\",\"values\":[[\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"],[\"0.6462\",\"0.6768\",\"0.6462\",\"0.6430\"]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"lightgrey\"},\"values\":[\"Metric\",\"Value\"]},\"type\":\"table\",\"domain\":{\"x\":[0.64,1.0],\"y\":[0.0,1.0]}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.54],\"title\":{\"text\":\"Predicted Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Label\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Confusion Matrix\",\"x\":0.27,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Performance Metrics\",\"x\":0.8200000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Fault Location - Evaluation Summary\"},\"height\":500,\"width\":900,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b4244415-458a-4cea-be4b-b1f38b6093b4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e8917cba-9341-421a-bc76-6351b6375361\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e8917cba-9341-421a-bc76-6351b6375361\")) {                    Plotly.newPlot(                        \"e8917cba-9341-421a-bc76-6351b6375361\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"showscale\":false,\"text\":[[652,124,131,0],[56,349,456,0],[258,127,525,0],[0,0,0,403]],\"texttemplate\":\"%{text}\",\"x\":[\"007\",\"014\",\"021\"],\"y\":[\"007\",\"014\",\"021\"],\"z\":[[652,124,131,0],[56,349,456,0],[258,127,525,0],[0,0,0,403]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"cells\":{\"align\":\"center\",\"values\":[[\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"],[\"0.6261\",\"0.6315\",\"0.6261\",\"0.6226\"]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"lightgrey\"},\"values\":[\"Metric\",\"Value\"]},\"type\":\"table\",\"domain\":{\"x\":[0.64,1.0],\"y\":[0.0,1.0]}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.54],\"title\":{\"text\":\"Predicted Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Label\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Confusion Matrix\",\"x\":0.27,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Performance Metrics\",\"x\":0.8200000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Crack Size - Evaluation Summary\"},\"height\":500,\"width\":900,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e8917cba-9341-421a-bc76-6351b6375361');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet\n",
        "\n",
        "https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "\n",
        "\n",
        "### Model Definition"
      ],
      "metadata": {
        "id": "32zHz6NsqoIW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-sPFfqDAq8P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Preparation"
      ],
      "metadata": {
        "id": "krZIsQJdqqeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "lFEDs3FWqvzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "K8kYSbSmqxTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long Short Term Memory (LSTM) Neural Network\n",
        "\n",
        "### Model Intuition\n",
        "\n",
        "LSTMs are a subtype of recurrent neural networks.\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "### Model Definition"
      ],
      "metadata": {
        "id": "Tn81_irNsNJZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "U07xDcGo6hfW"
      },
      "outputs": [],
      "source": [
        "class LSTM1D_pt(nn.Module):\n",
        "    def __init__(self, sequence_length=1024, hidden_size=128, num_layers=2, dropout_rate=0.3, num_fault_locations=4, num_crack_sizes=4):\n",
        "        super(LSTM1D_pt, self).__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=1,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=dropout_rate,\n",
        "                            bidirectional=False)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "        # Add a fully connected layer to expand features to 256\n",
        "        self.fc_expand = nn.Linear(hidden_size, 256)\n",
        "\n",
        "        # Output heads for three classification tasks\n",
        "        self.fault_detection_output = nn.Linear(256, 2)\n",
        "        self.fault_location_output = nn.Linear(256, num_fault_locations)\n",
        "        self.crack_size_output = nn.Linear(256, num_crack_sizes)\n",
        "\n",
        "        # Xavier initialization\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for layer in [self.fc_expand, self.fault_detection_output,\n",
        "                      self.fault_location_output, self.crack_size_output]:\n",
        "            nn.init.xavier_uniform_(layer.weight)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)  # [batch, seq_len, 1]\n",
        "        lstm_out, (h_n, _) = self.lstm(x)  # [batch, seq_len, hidden_size]\n",
        "\n",
        "        # Average pooling over sequence dimension\n",
        "        features = lstm_out.mean(dim=1)  # [batch, hidden_size]\n",
        "        features = self.bn(features)     # [batch, hidden_size]\n",
        "\n",
        "        # Expand to 256 dimensions\n",
        "        features = torch.relu(self.fc_expand(features))  # [batch, 256]\n",
        "\n",
        "        return (\n",
        "            torch.sigmoid(self.fault_detection_output(features)),\n",
        "            self.fault_location_output(features),\n",
        "            self.crack_size_output(features)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2qvTHho56hfW"
      },
      "outputs": [],
      "source": [
        "lstm_ctte = copy.deepcopy(pytorch_ctte)\n",
        "\n",
        "lstm_model = LSTM1D_pt(\n",
        "    sequence_length=1200,\n",
        "    hidden_size=256,\n",
        "    num_layers=2,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "lstm_ctte.load_model(lstm_model)\n",
        "\n",
        "lstm_ctte.load_optimizer(\n",
        "    torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Ut3rlFxx6hfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "a05bc664-3beb-446c-dba1-3617b0247b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25:   1%|▏         | 4/285 [00:53<1:02:38, 13.37s/it, loss=3.04]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3601191357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstm_ctte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm_ctte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlstm_ctte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1471538834.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# run the inputs through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mfault_detection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfault_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrack_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-145022301.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, seq_len, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, seq_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Average pooling over sequence dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lstm_ctte.prepare_data()\n",
        "lstm_ctte.train(epochs=25, batch_size=64)\n",
        "lstm_ctte.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juPVfhZY6hfW"
      },
      "outputs": [],
      "source": [
        "lstm_ctte.classification_report()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXH_Wzn06hfW"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}